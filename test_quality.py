#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DS News Aggregator - í’ˆì§ˆ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
í•„í„°ë§ ì •í™•ë„, ë²ˆì—­ í’ˆì§ˆ, ìš”ì•½ í’ˆì§ˆì„ ìƒì„¸ížˆ ê²€ì¦
"""

import json
import os
import sys
from datetime import datetime
from typing import Dict, List, Any, Optional
import time
import re

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from config import Config
from collectors.content_filter import ContentFilter
from processors.translator import Translator
from processors.summarizer import Summarizer

class QualityMetrics:
    """í’ˆì§ˆ ë©”íŠ¸ë¦­ í´ëž˜ìŠ¤"""
    
    def __init__(self):
        self.results = {
            'filtering': {
                'total_tested': 0,
                'correctly_filtered': 0,
                'false_positives': 0,
                'false_negatives': 0,
                'accuracy': 0,
                'precision': 0,
                'recall': 0
            },
            'translation': {
                'total_tested': 0,
                'successful': 0,
                'failed': 0,
                'skipped_korean': 0,
                'success_rate': 0,
                'avg_translation_time': 0
            },
            'summarization': {
                'total_tested': 0,
                'successful': 0,
                'three_sentences': 0,
                'keyword_coverage': 0,
                'success_rate': 0,
                'avg_summary_time': 0
            }
        }
    
    def calculate_filtering_metrics(self, test_results: List[Dict]):
        """í•„í„°ë§ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        total = len(test_results)
        true_positives = sum(1 for r in test_results if r['expected'] == True and r['actual'] == True)
        true_negatives = sum(1 for r in test_results if r['expected'] == False and r['actual'] == False)
        false_positives = sum(1 for r in test_results if r['expected'] == False and r['actual'] == True)
        false_negatives = sum(1 for r in test_results if r['expected'] == True and r['actual'] == False)
        
        accuracy = (true_positives + true_negatives) / total if total > 0 else 0
        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
        
        self.results['filtering'].update({
            'total_tested': total,
            'correctly_filtered': true_positives + true_negatives,
            'false_positives': false_positives,
            'false_negatives': false_negatives,
            'accuracy': accuracy * 100,
            'precision': precision * 100,
            'recall': recall * 100
        })
    
    def save_report(self, filename: str = None):
        """í’ˆì§ˆ ë¦¬í¬íŠ¸ ì €ìž¥"""
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"quality_report_{timestamp}.json"
        
        os.makedirs('reports', exist_ok=True)
        filepath = os.path.join('reports', filename)
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'metrics': self.results,
            'summary': self._generate_summary()
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        return filepath
    
    def _generate_summary(self) -> Dict[str, Any]:
        """í’ˆì§ˆ ìš”ì•½ ìƒì„±"""
        filtering = self.results['filtering']
        translation = self.results['translation']
        summarization = self.results['summarization']
        
        return {
            'overall_score': (
                filtering['accuracy'] * 0.4 +
                translation['success_rate'] * 0.3 +
                summarization['success_rate'] * 0.3
            ),
            'strengths': [],
            'weaknesses': [],
            'recommendations': []
        }

class FilteringQualityTester:
    """í•„í„°ë§ í’ˆì§ˆ í…ŒìŠ¤í„°"""
    
    def __init__(self, config: Config):
        self.config = config
        self.content_filter = ContentFilter(config)
        
    def create_test_dataset(self) -> List[Dict[str, Any]]:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±"""
        
        # ê³ í’ˆì§ˆ ê¸€ë“¤ (í†µê³¼í•´ì•¼ í•¨)
        high_quality_articles = [
            {
                'id': 'hq_1',
                'title': 'LLMì„ í™œìš©í•œ ì‹œê³„ì—´ ì˜ˆì¸¡ ë°©ë²•ë¡  ì™„ë²½ ê°€ì´ë“œ',
                'content': 'ë³¸ ì—°êµ¬ì—ì„œëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì‹œê³„ì—´ ë°ì´í„° ì˜ˆì¸¡ì— í™œìš©í•˜ëŠ” í˜ì‹ ì ì¸ ë°©ë²•ë¡ ì„ ì œì‹œí•©ë‹ˆë‹¤. Transformer ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ìœ¼ë¡œ ê¸°ì¡´ ARIMA ëª¨ë¸ ëŒ€ë¹„ 15% í–¥ìƒëœ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ê¸ˆìœµ ë°ì´í„°ì…‹ì„ í†µí•œ ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ì´ ë‹¤ì–‘í•œ ì‹œê³„ì—´ íŒ¨í„´ì—ì„œ ì¼ê´€ëœ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.',
                'source': 'naver_d2',
                'expected': True,
                'category': 'ê³ í’ˆì§ˆ_ê¸°ìˆ '
            },
            {
                'id': 'hq_2',
                'title': 'ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë°°í¬ë¥¼ ìœ„í•œ MLOps êµ¬í˜„ ì „ëžµ',
                'content': 'í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ì•ˆì •ì ìœ¼ë¡œ ë°°í¬í•˜ê¸° ìœ„í•œ MLOps íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤. Docker ì»¨í…Œì´ë„ˆí™”, Kubernetes ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜, ëª¨ë¸ ë²„ì €ë‹, A/B í…ŒìŠ¤íŒ…ê¹Œì§€ í¬í•¨í•œ ì™„ì „í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.',
                'source': 'kakao_tech',
                'expected': True,
                'category': 'ê³ í’ˆì§ˆ_ì‹¤ë¬´'
            },
            {
                'id': 'hq_3',
                'title': 'Deep Learning for Computer Vision: ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬í˜„',
                'content': 'Computer Vision í”„ë¡œì íŠ¸ì—ì„œ ë”¥ëŸ¬ë‹ì„ ì‹¤ì œë¡œ ì ìš©í•˜ëŠ” ê³¼ì •ì„ ìƒì„¸ížˆ ë‹¤ë£¹ë‹ˆë‹¤. CNN ì•„í‚¤í…ì²˜ ì„¤ê³„ë¶€í„° ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸ í›ˆë ¨, ì„±ëŠ¥ í‰ê°€ê¹Œì§€ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„í•©ë‹ˆë‹¤.',
                'source': 'ai_times',
                'expected': True,
                'category': 'ê³ í’ˆì§ˆ_íŠœí† ë¦¬ì–¼'
            },
            {
                'id': 'hq_4',
                'title': 'Advanced Time Series Analysis with Python',
                'content': 'Pythonì„ ì‚¬ìš©í•œ ê³ ê¸‰ ì‹œê³„ì—´ ë¶„ì„ ê¸°ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. SARIMA, Prophet, LSTMê¹Œì§€ ë‹¤ì–‘í•œ ëª¨ë¸ì„ ë¹„êµ ë¶„ì„í•˜ê³ , ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„°ì— ì ìš©í•œ ì‚¬ë¡€ë¥¼ í†µí•´ ê° ëª¨ë¸ì˜ ìž¥ë‹¨ì ì„ ì„¤ëª…í•©ë‹ˆë‹¤.',
                'source': 'reddit',
                'reddit_score': 42,
                'expected': True,
                'category': 'ê³ í’ˆì§ˆ_ë¶„ì„'
            }
        ]
        
        # ì¤‘í’ˆì§ˆ ê¸€ë“¤ (ê²½ê³„ì„  ì¼€ì´ìŠ¤)
        medium_quality_articles = [
            {
                'id': 'mq_1',
                'title': 'ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆ ê°œë… ì •ë¦¬',
                'content': 'ë¨¸ì‹ ëŸ¬ë‹ì˜ ê¸°ë³¸ ê°œë…ë“¤ì„ ì •ë¦¬í•´ë³´ê² ìŠµë‹ˆë‹¤. ì§€ë„í•™ìŠµ, ë¹„ì§€ë„í•™ìŠµ, ê°•í™”í•™ìŠµì˜ ì°¨ì´ì ê³¼ ê°ê°ì˜ ëŒ€í‘œì ì¸ ì•Œê³ ë¦¬ì¦˜ë“¤ì„ ê°„ë‹¨ížˆ ì†Œê°œí•©ë‹ˆë‹¤.',
                'source': 'naver_d2',
                'expected': False,  # ë„ˆë¬´ ê¸°ì´ˆì 
                'category': 'ì¤‘í’ˆì§ˆ_ê¸°ì´ˆ'
            },
            {
                'id': 'mq_2',
                'title': 'AI íŠ¸ë Œë“œ 2024',
                'content': '2024ë…„ ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ì˜ ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì‚´íŽ´ë³´ê² ìŠµë‹ˆë‹¤. ChatGPTì˜ ë“±ìž¥ ì´í›„ LLM ì‹œìž¥ì˜ ë³€í™”ì™€ ìƒˆë¡œìš´ ê¸°ìˆ ë“¤ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.',
                'source': 'ai_times',
                'expected': False,  # íŠ¸ë Œë“œ ì •ë¦¬ë§Œ
                'category': 'ì¤‘í’ˆì§ˆ_íŠ¸ë Œë“œ'
            }
        ]
        
        # ì €í’ˆì§ˆ ê¸€ë“¤ (ì°¨ë‹¨ë˜ì–´ì•¼ í•¨)
        low_quality_articles = [
            {
                'id': 'lq_1',
                'title': 'ë¨¸ì‹ ëŸ¬ë‹ ì±… ì¶”ì²œí•´ì£¼ì„¸ìš”!!!',
                'content': 'ë¨¸ì‹ ëŸ¬ë‹ì„ ê³µë¶€í•˜ë ¤ê³  í•˜ëŠ”ë° ì–´ë–¤ ì±…ì´ ì¢‹ì„ê¹Œìš”? ì¶”ì²œí•´ì£¼ì„¸ìš”! ì´ˆë³´ìžë„ ì´í•´í•  ìˆ˜ ìžˆëŠ” ì±…ìœ¼ë¡œ ë¶€íƒë“œë¦½ë‹ˆë‹¤!!',
                'source': 'reddit',
                'reddit_score': 3,
                'expected': False,
                'category': 'ì €í’ˆì§ˆ_ì¶”ì²œìš”ì²­'
            },
            {
                'id': 'lq_2',
                'title': 'ì´ ëª¨ë¸ ê²°ê³¼ ì–´ë–»ê²Œ ìƒê°í•˜ì„¸ìš”?',
                'content': 'CNN ëª¨ë¸ì„ ë§Œë“¤ì–´ë´¤ëŠ”ë° ì •í™•ë„ê°€ 85%ê°€ ë‚˜ì™”ì–´ìš”. ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë‚˜ìš”? ë” ê°œì„ í•  ë°©ë²•ì´ ìžˆì„ê¹Œìš”?',
                'source': 'reddit',
                'reddit_score': 7,
                'expected': False,
                'category': 'ì €í’ˆì§ˆ_ì˜ê²¬ìš”ì²­'
            },
            {
                'id': 'lq_3',
                'title': 'íŒŒì´ì¬ ì„¤ì¹˜ê°€ ì•ˆë¼ìš” ã… ã… ',
                'content': 'íŒŒì´ì¬ ì„¤ì¹˜í•˜ëŠ”ë° ìžê¾¸ ì˜¤ë¥˜ê°€ ë‚˜ìš”ã… ã…  ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”? ë„ì™€ì£¼ì„¸ìš”!!!',
                'source': 'reddit',
                'reddit_score': 1,
                'expected': False,
                'category': 'ì €í’ˆì§ˆ_ê¸°ìˆ ë¬¸ì œ'
            },
            {
                'id': 'lq_4',
                'title': 'ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ ì–´ë•Œìš”?',
                'content': 'ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ë¡œ ì „ì§í•˜ë ¤ê³  í•˜ëŠ”ë° ì–´ë–¨ê¹Œìš”? ì „ë§ì´ ì¢‹ë‚˜ìš”? ì—°ë´‰ì€ ì–´ëŠ ì •ë„ ë˜ë‚˜ìš”?',
                'source': 'reddit',
                'reddit_score': 2,
                'expected': False,
                'category': 'ì €í’ˆì§ˆ_ì§„ë¡œìƒë‹´'
            }
        ]
        
        return high_quality_articles + medium_quality_articles + low_quality_articles
    
    def test_filtering_accuracy(self) -> List[Dict[str, Any]]:
        """í•„í„°ë§ ì •í™•ë„ í…ŒìŠ¤íŠ¸"""
        print("ðŸ” í•„í„°ë§ ì •í™•ë„ í…ŒìŠ¤íŠ¸ ì‹œìž‘...")
        
        test_dataset = self.create_test_dataset()
        results = []
        
        for article in test_dataset:
            # ì ìˆ˜ ê³„ì‚°
            if article['source'] == 'reddit':
                score = self.content_filter._calculate_reddit_score(
                    article['title'],
                    article['content'],
                    article.get('reddit_score', 0)
                )
            else:
                score = self.content_filter._calculate_blog_score(
                    article['title'],
                    article['content'],
                    article['source']
                )
            
            # í•„í„°ë§ ê²°ê³¼ (70ì  ì´ìƒ í†µê³¼)
            passed = score >= self.config.MIN_SCORE_THRESHOLD
            expected = article['expected']
            
            result = {
                'id': article['id'],
                'title': article['title'][:50] + '...',
                'category': article['category'],
                'score': score,
                'expected': expected,
                'actual': passed,
                'correct': expected == passed
            }
            
            results.append(result)
            
            status = "âœ… ì •ë‹µ" if result['correct'] else "âŒ ì˜¤ë‹µ"
            print(f"  {article['id']}: {score:>3.0f}ì  -> {'í†µê³¼' if passed else 'ì°¨ë‹¨'} ({article['category']}) {status}")
        
        return results
    
    def analyze_filtering_errors(self, results: List[Dict]) -> Dict[str, Any]:
        """í•„í„°ë§ ì˜¤ë¥˜ ë¶„ì„"""
        errors = [r for r in results if not r['correct']]
        
        error_analysis = {
            'false_positives': [r for r in errors if r['actual'] == True and r['expected'] == False],
            'false_negatives': [r for r in errors if r['actual'] == False and r['expected'] == True],
            'common_patterns': {}
        }
        
        print(f"\nðŸ” ì˜¤ë¥˜ ë¶„ì„ ({len(errors)}ê°œ ì˜¤ë¥˜):")
        
        if error_analysis['false_positives']:
            print(f"  ðŸ”´ ê±°ì§“ ì–‘ì„± (ìž˜ëª» í†µê³¼): {len(error_analysis['false_positives'])}ê°œ")
            for fp in error_analysis['false_positives']:
                print(f"    - {fp['title']} ({fp['score']:.0f}ì )")
        
        if error_analysis['false_negatives']:
            print(f"  ðŸ”´ ê±°ì§“ ìŒì„± (ìž˜ëª» ì°¨ë‹¨): {len(error_analysis['false_negatives'])}ê°œ")
            for fn in error_analysis['false_negatives']:
                print(f"    - {fn['title']} ({fn['score']:.0f}ì )")
        
        return error_analysis

class TranslationQualityTester:
    """ë²ˆì—­ í’ˆì§ˆ í…ŒìŠ¤í„°"""
    
    def __init__(self, config: Config):
        self.config = config
        self.translator = Translator(config)
        
    def create_translation_testset(self) -> List[Dict[str, Any]]:
        """ë²ˆì—­ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±"""
        return [
            {
                'id': 'tr_1',
                'text': 'Machine learning algorithms automatically identify patterns in large datasets.',
                'expected_keywords': ['ë¨¸ì‹ ëŸ¬ë‹', 'ì•Œê³ ë¦¬ì¦˜', 'íŒ¨í„´', 'ë°ì´í„°'],
                'difficulty': 'easy'
            },
            {
                'id': 'tr_2', 
                'text': 'Deep neural networks with convolutional layers excel at computer vision tasks.',
                'expected_keywords': ['ë”¥', 'ì‹ ê²½ë§', 'ì»¨ë³¼ë£¨ì…˜', 'ì»´í“¨í„° ë¹„ì „'],
                'difficulty': 'medium'
            },
            {
                'id': 'tr_3',
                'text': 'Transformer architectures leverage self-attention mechanisms to process sequential data efficiently.',
                'expected_keywords': ['íŠ¸ëžœìŠ¤í¬ë¨¸', 'ì…€í”„ì–´í…ì…˜', 'ìˆœì°¨', 'ë°ì´í„°'],
                'difficulty': 'hard'
            },
            {
                'id': 'tr_4',
                'text': 'Gradient descent optimization iteratively updates model parameters to minimize loss functions.',
                'expected_keywords': ['ê²½ì‚¬', 'í•˜ê°•', 'ìµœì í™”', 'ë§¤ê°œë³€ìˆ˜', 'ì†ì‹¤'],
                'difficulty': 'hard'
            },
            {
                'id': 'tr_5',
                'text': 'Cross-validation techniques help evaluate model performance and prevent overfitting.',
                'expected_keywords': ['êµì°¨', 'ê²€ì¦', 'ì„±ëŠ¥', 'ê³¼ì í•©'],
                'difficulty': 'medium'
            },
            {
                'id': 'tr_6',
                'text': 'Time series forecasting models predict future values based on historical patterns.',
                'expected_keywords': ['ì‹œê³„ì—´', 'ì˜ˆì¸¡', 'ë¯¸ëž˜', 'íŒ¨í„´'],
                'difficulty': 'easy'
            }
        ]
    
    def test_translation_quality(self) -> List[Dict[str, Any]]:
        """ë²ˆì—­ í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""
        print("ðŸŒ ë²ˆì—­ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì‹œìž‘...")
        
        test_dataset = self.create_translation_testset()
        results = []
        
        for test_case in test_dataset:
            print(f"  ðŸ“ {test_case['id']} ({test_case['difficulty']})...")
            
            start_time = time.time()
            
            try:
                result = self.translator.translate_text(test_case['text'], 'ko')
                
                translation_time = time.time() - start_time
                
                if result['success']:
                    translated_text = result['translated_text']
                    
                    # í‚¤ì›Œë“œ ì»¤ë²„ë¦¬ì§€ ê³„ì‚°
                    keyword_coverage = 0
                    for keyword in test_case['expected_keywords']:
                        if keyword in translated_text:
                            keyword_coverage += 1
                    
                    coverage_rate = keyword_coverage / len(test_case['expected_keywords']) * 100
                    
                    # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
                    quality_score = min(100, coverage_rate * 1.2 + 20)  # ê¸°ë³¸ 20ì  + í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤
                    
                    test_result = {
                        'id': test_case['id'],
                        'original': test_case['text'][:60] + '...',
                        'translated': translated_text[:60] + '...',
                        'difficulty': test_case['difficulty'],
                        'success': True,
                        'keyword_coverage': coverage_rate,
                        'quality_score': quality_score,
                        'translation_time': translation_time,
                        'service': result.get('service', 'unknown')
                    }
                    
                    print(f"    âœ… ë²ˆì—­ ì„±ê³µ (í’ˆì§ˆ: {quality_score:.1f}ì , í‚¤ì›Œë“œ: {keyword_coverage}/{len(test_case['expected_keywords'])})")
                    print(f"       ì›ë¬¸: {test_case['text'][:80]}...")
                    print(f"       ë²ˆì—­: {translated_text[:80]}...")
                
                else:
                    test_result = {
                        'id': test_case['id'],
                        'original': test_case['text'][:60] + '...',
                        'translated': '',
                        'difficulty': test_case['difficulty'],
                        'success': False,
                        'keyword_coverage': 0,
                        'quality_score': 0,
                        'translation_time': translation_time,
                        'error': result.get('error', 'Unknown error')
                    }
                    
                    print(f"    âŒ ë²ˆì—­ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                
            except Exception as e:
                test_result = {
                    'id': test_case['id'],
                    'original': test_case['text'][:60] + '...',
                    'translated': '',
                    'difficulty': test_case['difficulty'],
                    'success': False,
                    'keyword_coverage': 0,
                    'quality_score': 0,
                    'translation_time': time.time() - start_time,
                    'error': str(e)
                }
                
                print(f"    ðŸ’¥ ë²ˆì—­ ì˜¤ë¥˜: {e}")
            
            results.append(test_result)
            time.sleep(1)  # API ì œí•œ ëŒ€ì‘
        
        return results
    
    def analyze_translation_quality(self, results: List[Dict]) -> Dict[str, Any]:
        """ë²ˆì—­ í’ˆì§ˆ ë¶„ì„"""
        successful = [r for r in results if r['success']]
        failed = [r for r in results if not r['success']]
        
        analysis = {
            'success_rate': len(successful) / len(results) * 100 if results else 0,
            'avg_quality_score': sum(r['quality_score'] for r in successful) / len(successful) if successful else 0,
            'avg_translation_time': sum(r['translation_time'] for r in results) / len(results) if results else 0,
            'difficulty_breakdown': {}
        }
        
        # ë‚œì´ë„ë³„ ë¶„ì„
        for difficulty in ['easy', 'medium', 'hard']:
            difficulty_results = [r for r in results if r['difficulty'] == difficulty]
            if difficulty_results:
                difficulty_success = [r for r in difficulty_results if r['success']]
                analysis['difficulty_breakdown'][difficulty] = {
                    'total': len(difficulty_results),
                    'successful': len(difficulty_success),
                    'success_rate': len(difficulty_success) / len(difficulty_results) * 100,
                    'avg_quality': sum(r['quality_score'] for r in difficulty_success) / len(difficulty_success) if difficulty_success else 0
                }
        
        print(f"\nðŸ“Š ë²ˆì—­ í’ˆì§ˆ ë¶„ì„:")
        print(f"  ì „ì²´ ì„±ê³µë¥ : {analysis['success_rate']:.1f}%")
        print(f"  í‰ê·  í’ˆì§ˆì ìˆ˜: {analysis['avg_quality_score']:.1f}ì ")
        print(f"  í‰ê·  ë²ˆì—­ì‹œê°„: {analysis['avg_translation_time']:.3f}ì´ˆ")
        
        print(f"  ë‚œì´ë„ë³„ ì„±ê³µë¥ :")
        for difficulty, stats in analysis['difficulty_breakdown'].items():
            print(f"    {difficulty}: {stats['success_rate']:.1f}% ({stats['successful']}/{stats['total']})")
        
        return analysis

class SummarizationQualityTester:
    """ìš”ì•½ í’ˆì§ˆ í…ŒìŠ¤í„°"""
    
    def __init__(self, config: Config):
        self.config = config
        self.summarizer = Summarizer(config)
    
    def create_summarization_testset(self) -> List[Dict[str, Any]]:
        """ìš”ì•½ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±"""
        return [
            {
                'id': 'sum_1',
                'title': 'ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìžì—°ì–´ ì²˜ë¦¬',
                'content': '''ìžì—°ì–´ ì²˜ë¦¬(Natural Language Processing, NLP)ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ì²˜ë¦¬í•  ìˆ˜ ìžˆë„ë¡ í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ìž…ë‹ˆë‹¤. ìµœê·¼ ë”¥ëŸ¬ë‹ ê¸°ìˆ ì˜ ë°œì „ìœ¼ë¡œ NLP ë¶„ì•¼ì—ì„œ í˜ì‹ ì ì¸ ì„±ê³¼ë¥¼ ê±°ë‘ê³  ìžˆìŠµë‹ˆë‹¤. 

íŠ¹ížˆ Transformer ì•„í‚¤í…ì²˜ì˜ ë“±ìž¥ì€ NLP ë¶„ì•¼ì˜ íŒ¨ëŸ¬ë‹¤ìž„ì„ ì™„ì „ížˆ ë°”ê¾¸ì–´ ë†“ì•˜ìŠµë‹ˆë‹¤. BERT, GPT ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë“¤ì´ ë‹¤ì–‘í•œ NLP íƒœìŠ¤í¬ì—ì„œ ì¸ê°„ ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìžˆìŠµë‹ˆë‹¤. 

ì´ëŸ¬í•œ ê¸°ìˆ ë“¤ì€ ë²ˆì—­, ê°ì • ë¶„ì„, í…ìŠ¤íŠ¸ ìš”ì•½, ì§ˆì˜ì‘ë‹µ ë“± ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì—­ì—ì„œë„ ê´‘ë²”ìœ„í•˜ê²Œ í™œìš©ë˜ê³  ìžˆìŠµë‹ˆë‹¤. ì•žìœ¼ë¡œ ë”ìš± ë°œì „ëœ ì–¸ì–´ ëª¨ë¸ë“¤ì´ ë“±ìž¥í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë©°, NLP ê¸°ìˆ ì€ ìš°ë¦¬ ì¼ìƒìƒí™œì— ë”ìš± ê¹Šìˆ™ì´ ë“¤ì–´ì˜¬ ê²ƒìž…ë‹ˆë‹¤.''',
                'key_concepts': ['NLP', 'ë”¥ëŸ¬ë‹', 'Transformer', 'BERT', 'GPT', 'ì–¸ì–´ëª¨ë¸'],
                'expected_sentences': 3,
                'difficulty': 'medium'
            },
            {
                'id': 'sum_2',
                'title': 'ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ ë°©ë²•ë¡ ',
                'content': '''ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ì€ ì‹œê°„ì— ë”°ë¼ ë³€í™”í•˜ëŠ” ë°ì´í„°ì˜ íŒ¨í„´ì„ íŒŒì•…í•˜ê³  ë¯¸ëž˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¶„ì„ ê¸°ë²•ìž…ë‹ˆë‹¤. ì£¼ì‹ ê°€ê²©, ë‚ ì”¨ ë°ì´í„°, íŒë§¤ëŸ‰ ë“± ì‹œê°„ì˜ íë¦„ì— ë”°ë¼ ìˆ˜ì§‘ë˜ëŠ” ëŒ€ë¶€ë¶„ì˜ ë°ì´í„°ê°€ ì‹œê³„ì—´ ë°ì´í„°ì— í•´ë‹¹í•©ë‹ˆë‹¤.

ì „í†µì ì¸ ì‹œê³„ì—´ ë¶„ì„ ë°©ë²•ìœ¼ë¡œëŠ” ARIMA, ì§€ìˆ˜ í‰í™œë²•, ê³„ì ˆ ë¶„í•´ ë“±ì´ ìžˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°©ë²•ë“¤ì€ ì„ í˜•ì ì¸ íŒ¨í„´ì„ ìž˜ í¬ì°©í•˜ì§€ë§Œ, ë³µìž¡í•œ ë¹„ì„ í˜• íŒ¨í„´ì„ ì²˜ë¦¬í•˜ëŠ” ë°ëŠ” í•œê³„ê°€ ìžˆìŠµë‹ˆë‹¤.

ìµœê·¼ì—ëŠ” LSTM, GRUì™€ ê°™ì€ ìˆœí™˜ ì‹ ê²½ë§(RNN) ê³„ì—´ì˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ë“¤ì´ ì‹œê³„ì—´ ì˜ˆì¸¡ì— í™œìš©ë˜ê³  ìžˆìŠµë‹ˆë‹¤. íŠ¹ížˆ Prophet, Transformer ê¸°ë°˜ ëª¨ë¸ë“¤ì€ ê³„ì ˆì„±ê³¼ íŠ¸ë Œë“œë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ê¸°ì¡´ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ì—ì„œëŠ” ì´ëŸ¬í•œ ê¸°ë²•ë“¤ì„ ì¡°í•©í•˜ì—¬ ìˆ˜ìš” ì˜ˆì¸¡, ìž¬ê³  ê´€ë¦¬, ë¦¬ìŠ¤í¬ ë¶„ì„ ë“±ì— í™œìš©í•˜ê³  ìžˆìŠµë‹ˆë‹¤.''',
                'key_concepts': ['ì‹œê³„ì—´', 'ARIMA', 'LSTM', 'Prophet', 'ì˜ˆì¸¡', 'íŒ¨í„´'],
                'expected_sentences': 3,
                'difficulty': 'medium'
            },
            {
                'id': 'sum_3',
                'title': 'MLOpsì™€ ëª¨ë¸ ë°°í¬ ì „ëžµ',
                'content': '''MLOps(Machine Learning Operations)ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ê°œë°œë¶€í„° ë°°í¬, ëª¨ë‹ˆí„°ë§ê¹Œì§€ì˜ ì „ì²´ ìƒëª…ì£¼ê¸°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ë°©ë²•ë¡ ìž…ë‹ˆë‹¤. DevOpsì˜ ê°œë…ì„ ë¨¸ì‹ ëŸ¬ë‹ ì˜ì—­ì— ì ìš©í•œ ê²ƒìœ¼ë¡œ, ëª¨ë¸ì˜ ì§€ì†ì  í†µí•©ê³¼ ë°°í¬ë¥¼ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

MLOpsì˜ í•µì‹¬ êµ¬ì„± ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì²«ì§¸, ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œì„ í†µí•œ ì½”ë“œì™€ ë°ì´í„°ì˜ ì¶”ì  ê°€ëŠ¥ì„± í™•ë³´ìž…ë‹ˆë‹¤. Gitê³¼ DVCë¥¼ í™œìš©í•˜ì—¬ ì‹¤í—˜ê³¼ ë°ì´í„°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë‘˜ì§¸, ìžë™í™”ëœ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ìž…ë‹ˆë‹¤. CI/CD íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ëª¨ë¸ í›ˆë ¨ë¶€í„° ë°°í¬ê¹Œì§€ ìžë™í™”í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. 

ì…‹ì§¸, ëª¨ë‹ˆí„°ë§ê³¼ ë¡œê¹… ì‹œìŠ¤í…œìž…ë‹ˆë‹¤. ë°°í¬ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³ , ë°ì´í„° ë“œë¦¬í”„íŠ¸ë‚˜ ëª¨ë¸ ì„±ëŠ¥ ì €í•˜ë¥¼ ë¹ ë¥´ê²Œ ê°ì§€í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë„·ì§¸, ì»¨í…Œì´ë„ˆí™”ì™€ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ìž…ë‹ˆë‹¤. Dockerì™€ Kubernetesë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ì„ ì•ˆì •ì ìœ¼ë¡œ ë°°í¬í•˜ê³  í™•ìž¥í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

ì‹¤ì œ ê¸°ì—…ì—ì„œëŠ” Kubeflow, MLflow, Amazon SageMaker ë“±ì˜ í”Œëž«í¼ì„ í™œìš©í•˜ì—¬ MLOpsë¥¼ êµ¬í˜„í•˜ê³  ìžˆìŠµë‹ˆë‹¤.''',
                'key_concepts': ['MLOps', 'DevOps', 'ë°°í¬', 'ëª¨ë‹ˆí„°ë§', 'ìžë™í™”', 'Docker'],
                'expected_sentences': 3,
                'difficulty': 'hard'
            }
        ]
    
    def test_summarization_quality(self) -> List[Dict[str, Any]]:
        """ìš”ì•½ í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""
        print("ðŸ“„ ìš”ì•½ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì‹œìž‘...")
        
        test_dataset = self.create_summarization_testset()
        results = []
        
        for test_case in test_dataset:
            print(f"  ðŸ“ {test_case['id']} ({test_case['difficulty']})...")
            
            start_time = time.time()
            
            try:
                result = self.summarizer.summarize_text(test_case['title'], test_case['content'])
                
                summarization_time = time.time() - start_time
                
                if result['success']:
                    summary = result['summary']
                    sentences_count = result['sentences_count']
                    
                    # í‚¤ì›Œë“œ ì»¤ë²„ë¦¬ì§€ ê³„ì‚°
                    keyword_coverage = 0
                    for concept in test_case['key_concepts']:
                        if concept.lower() in summary.lower():
                            keyword_coverage += 1
                    
                    coverage_rate = keyword_coverage / len(test_case['key_concepts']) * 100
                    
                    # ë¬¸ìž¥ ìˆ˜ ì •í™•ë„
                    sentence_accuracy = 100 if sentences_count == 3 else max(0, 100 - abs(sentences_count - 3) * 20)
                    
                    # ì „ì²´ í’ˆì§ˆ ì ìˆ˜
                    quality_score = (coverage_rate * 0.6 + sentence_accuracy * 0.4)
                    
                    test_result = {
                        'id': test_case['id'],
                        'title': test_case['title'],
                        'summary': summary,
                        'difficulty': test_case['difficulty'],
                        'success': True,
                        'sentences_count': sentences_count,
                        'expected_sentences': test_case['expected_sentences'],
                        'keyword_coverage': coverage_rate,
                        'quality_score': quality_score,
                        'summarization_time': summarization_time,
                        'service': result.get('service', 'unknown')
                    }
                    
                    print(f"    âœ… ìš”ì•½ ì„±ê³µ (í’ˆì§ˆ: {quality_score:.1f}ì )")
                    print(f"       ë¬¸ìž¥ìˆ˜: {sentences_count}/3, í‚¤ì›Œë“œ: {keyword_coverage}/{len(test_case['key_concepts'])}")
                    print(f"       ìš”ì•½: {summary[:100]}...")
                
                else:
                    test_result = {
                        'id': test_case['id'],
                        'title': test_case['title'],
                        'summary': '',
                        'difficulty': test_case['difficulty'],
                        'success': False,
                        'sentences_count': 0,
                        'expected_sentences': test_case['expected_sentences'],
                        'keyword_coverage': 0,
                        'quality_score': 0,
                        'summarization_time': summarization_time,
                        'error': result.get('error', 'Unknown error')
                    }
                    
                    print(f"    âŒ ìš”ì•½ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
                
            except Exception as e:
                test_result = {
                    'id': test_case['id'],
                    'title': test_case['title'],
                    'summary': '',
                    'difficulty': test_case['difficulty'],
                    'success': False,
                    'sentences_count': 0,
                    'expected_sentences': test_case['expected_sentences'],
                    'keyword_coverage': 0,
                    'quality_score': 0,
                    'summarization_time': time.time() - start_time,
                    'error': str(e)
                }
                
                print(f"    ðŸ’¥ ìš”ì•½ ì˜¤ë¥˜: {e}")
            
            results.append(test_result)
            time.sleep(3)  # Gemini API ì œí•œ ëŒ€ì‘
        
        return results
    
    def analyze_summarization_quality(self, results: List[Dict]) -> Dict[str, Any]:
        """ìš”ì•½ í’ˆì§ˆ ë¶„ì„"""
        successful = [r for r in results if r['success']]
        three_sentence_summaries = [r for r in successful if r['sentences_count'] == 3]
        
        analysis = {
            'success_rate': len(successful) / len(results) * 100 if results else 0,
            'three_sentence_rate': len(three_sentence_summaries) / len(results) * 100 if results else 0,
            'avg_quality_score': sum(r['quality_score'] for r in successful) / len(successful) if successful else 0,
            'avg_keyword_coverage': sum(r['keyword_coverage'] for r in successful) / len(successful) if successful else 0,
            'avg_summarization_time': sum(r['summarization_time'] for r in results) / len(results) if results else 0,
            'difficulty_breakdown': {}
        }
        
        # ë‚œì´ë„ë³„ ë¶„ì„
        for difficulty in ['easy', 'medium', 'hard']:
            difficulty_results = [r for r in results if r['difficulty'] == difficulty]
            if difficulty_results:
                difficulty_success = [r for r in difficulty_results if r['success']]
                analysis['difficulty_breakdown'][difficulty] = {
                    'total': len(difficulty_results),
                    'successful': len(difficulty_success),
                    'success_rate': len(difficulty_success) / len(difficulty_results) * 100,
                    'avg_quality': sum(r['quality_score'] for r in difficulty_success) / len(difficulty_success) if difficulty_success else 0
                }
        
        print(f"\nðŸ“Š ìš”ì•½ í’ˆì§ˆ ë¶„ì„:")
        print(f"  ì „ì²´ ì„±ê³µë¥ : {analysis['success_rate']:.1f}%")
        print(f"  3ë¬¸ìž¥ ìš”ì•½ë¥ : {analysis['three_sentence_rate']:.1f}%")
        print(f"  í‰ê·  í’ˆì§ˆì ìˆ˜: {analysis['avg_quality_score']:.1f}ì ")
        print(f"  í‰ê·  í‚¤ì›Œë“œ ì»¤ë²„ë¦¬ì§€: {analysis['avg_keyword_coverage']:.1f}%")
        print(f"  í‰ê·  ìš”ì•½ì‹œê°„: {analysis['avg_summarization_time']:.3f}ì´ˆ")
        
        return analysis

def run_quality_tests():
    """ì „ì²´ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ðŸŽ¯ DS News Aggregator í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹œìž‘")
    print("="*60)
    
    config = Config()
    metrics = QualityMetrics()
    
    try:
        # 1. í•„í„°ë§ í’ˆì§ˆ í…ŒìŠ¤íŠ¸
        print("\n1ï¸âƒ£ í•„í„°ë§ í’ˆì§ˆ í…ŒìŠ¤íŠ¸")
        print("-" * 30)
        
        filtering_tester = FilteringQualityTester(config)
        filtering_results = filtering_tester.test_filtering_accuracy()
        filtering_analysis = filtering_tester.analyze_filtering_errors(filtering_results)
        
        metrics.calculate_filtering_metrics(filtering_results)
        
        # 2. ë²ˆì—­ í’ˆì§ˆ í…ŒìŠ¤íŠ¸
        print("\n2ï¸âƒ£ ë²ˆì—­ í’ˆì§ˆ í…ŒìŠ¤íŠ¸")
        print("-" * 30)
        
        translation_tester = TranslationQualityTester(config)
        translation_results = translation_tester.test_translation_quality()
        translation_analysis = translation_tester.analyze_translation_quality(translation_results)
        
        metrics.results['translation'].update({
            'total_tested': len(translation_results),
            'successful': len([r for r in translation_results if r['success']]),
            'success_rate': translation_analysis['success_rate'],
            'avg_translation_time': translation_analysis['avg_translation_time']
        })
        
        # 3. ìš”ì•½ í’ˆì§ˆ í…ŒìŠ¤íŠ¸
        print("\n3ï¸âƒ£ ìš”ì•½ í’ˆì§ˆ í…ŒìŠ¤íŠ¸")
        print("-" * 30)
        
        summarization_tester = SummarizationQualityTester(config)
        summarization_results = summarization_tester.test_summarization_quality()
        summarization_analysis = summarization_tester.analyze_summarization_quality(summarization_results)
        
        metrics.results['summarization'].update({
            'total_tested': len(summarization_results),
            'successful': len([r for r in summarization_results if r['success']]),
            'success_rate': summarization_analysis['success_rate'],
            'three_sentences': summarization_analysis['three_sentence_rate'],
            'keyword_coverage': summarization_analysis['avg_keyword_coverage'],
            'avg_summary_time': summarization_analysis['avg_summarization_time']
        })
        
        # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
        print("\nðŸ“Š ìµœì¢… í’ˆì§ˆ ë¦¬í¬íŠ¸")
        print("="*60)
        
        print(f"ðŸ” í•„í„°ë§ í’ˆì§ˆ:")
        print(f"   ì •í™•ë„: {metrics.results['filtering']['accuracy']:.1f}%")
        print(f"   ì •ë°€ë„: {metrics.results['filtering']['precision']:.1f}%")
        print(f"   ìž¬í˜„ìœ¨: {metrics.results['filtering']['recall']:.1f}%")
        
        print(f"ðŸŒ ë²ˆì—­ í’ˆì§ˆ:")
        print(f"   ì„±ê³µë¥ : {metrics.results['translation']['success_rate']:.1f}%")
        print(f"   í‰ê·  ì‹œê°„: {metrics.results['translation']['avg_translation_time']:.3f}ì´ˆ")
        
        print(f"ðŸ“„ ìš”ì•½ í’ˆì§ˆ:")
        print(f"   ì„±ê³µë¥ : {metrics.results['summarization']['success_rate']:.1f}%")
        print(f"   3ë¬¸ìž¥ ë¹„ìœ¨: {metrics.results['summarization']['three_sentences']:.1f}%")
        print(f"   í‚¤ì›Œë“œ ì»¤ë²„ë¦¬ì§€: {metrics.results['summarization']['keyword_coverage']:.1f}%")
        
        # ì „ì²´ í’ˆì§ˆ ì ìˆ˜
        overall_score = (
            metrics.results['filtering']['accuracy'] * 0.4 +
            metrics.results['translation']['success_rate'] * 0.3 +
            metrics.results['summarization']['success_rate'] * 0.3
        )
        
        print(f"\nðŸŽ¯ ì „ì²´ í’ˆì§ˆ ì ìˆ˜: {overall_score:.1f}ì ")
        
        if overall_score >= 80:
            print("ðŸŽ‰ ìš°ìˆ˜í•œ í’ˆì§ˆ - ë°°í¬ ì¤€ë¹„ ì™„ë£Œ!")
        elif overall_score >= 70:
            print("âœ… ì–‘í˜¸í•œ í’ˆì§ˆ - ì¼ë¶€ ê°œì„  í•„ìš”")
        else:
            print("âš ï¸  í’ˆì§ˆ ê°œì„  í•„ìš” - ì¶”ê°€ ìµœì í™” ê¶Œìž¥")
        
        # ë¦¬í¬íŠ¸ ì €ìž¥
        report_path = metrics.save_report()
        print(f"\nðŸ“‹ ìƒì„¸ ë¦¬í¬íŠ¸: {report_path}")
        
        return overall_score >= 70
        
    except Exception as e:
        print(f"ðŸ’¥ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == '__main__':
    success = run_quality_tests()
    sys.exit(0 if success else 1)
