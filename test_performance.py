#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DS News Aggregator - ì„±ëŠ¥ ì²´í¬ ìŠ¤í¬ë¦½íŠ¸
ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, API í˜¸ì¶œ íšŸìˆ˜, ì‹¤í–‰ ì‹œê°„ì„ ìƒì„¸í•˜ê²Œ ì¶”ì 
"""

import time
import psutil
import json
import os
import sys
from datetime import datetime
from typing import Dict, List, Any
import threading
import matplotlib.pyplot as plt
import seaborn as sns

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from config import Config
from processors.pipeline import DSNewsPipeline

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str = "Performance Test"):
        self.name = name
        self.process = psutil.Process()
        self.monitoring = False
        self.data = {
            'timestamps': [],
            'cpu_percent': [],
            'memory_mb': [],
            'memory_percent': [],
            'io_read_bytes': [],
            'io_write_bytes': [],
            'network_sent': [],
            'network_recv': []
        }
        self.start_time = None
        self.end_time = None
        self.api_calls = {
            'reddit': [],
            'gemini': [],
            'googletrans': [],
            'rss': []
        }
        
    def start(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.start_time = time.time()
        self.monitoring = True
        
        # ì´ˆê¸° ë„¤íŠ¸ì›Œí¬/IO ìƒíƒœ
        self.initial_io = self.process.io_counters()
        self.initial_net = psutil.net_io_counters()
        
        # ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹œì‘
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
        
        print(f"ğŸ” ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘: {self.name}")
    
    def stop(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.end_time = time.time()
        self.monitoring = False
        
        if hasattr(self, 'monitor_thread'):
            self.monitor_thread.join(timeout=1)
            
        print(f"â¹ï¸  ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ: {self.name}")
        
    def _monitor_loop(self):
        """ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.monitoring:
            try:
                timestamp = time.time() - self.start_time
                
                # CPU ì‚¬ìš©ë¥ 
                cpu_percent = self.process.cpu_percent(interval=0.1)
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
                memory_info = self.process.memory_info()
                memory_mb = memory_info.rss / 1024 / 1024
                memory_percent = self.process.memory_percent()
                
                # I/O ì •ë³´
                current_io = self.process.io_counters()
                io_read = (current_io.read_bytes - self.initial_io.read_bytes) / 1024 / 1024
                io_write = (current_io.write_bytes - self.initial_io.write_bytes) / 1024 / 1024
                
                # ë„¤íŠ¸ì›Œí¬ ì •ë³´ (ì „ì²´ ì‹œìŠ¤í…œ)
                current_net = psutil.net_io_counters()
                net_sent = (current_net.bytes_sent - self.initial_net.bytes_sent) / 1024 / 1024
                net_recv = (current_net.bytes_recv - self.initial_net.bytes_recv) / 1024 / 1024
                
                # ë°ì´í„° ì €ì¥
                self.data['timestamps'].append(timestamp)
                self.data['cpu_percent'].append(cpu_percent)
                self.data['memory_mb'].append(memory_mb)
                self.data['memory_percent'].append(memory_percent)
                self.data['io_read_bytes'].append(io_read)
                self.data['io_write_bytes'].append(io_write)
                self.data['network_sent'].append(net_sent)
                self.data['network_recv'].append(net_recv)
                
                time.sleep(1)  # 1ì´ˆ ê°„ê²©
                
            except Exception as e:
                print(f"âš ï¸  ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                break
    
    def record_api_call(self, api_type: str, duration: float, success: bool, details: str = ""):
        """API í˜¸ì¶œ ê¸°ë¡"""
        if api_type in self.api_calls:
            self.api_calls[api_type].append({
                'timestamp': time.time() - (self.start_time or time.time()),
                'duration': duration,
                'success': success,
                'details': details
            })
    
    def get_duration(self) -> float:
        """ì´ ì‹¤í–‰ ì‹œê°„"""
        if self.start_time and self.end_time:
            return self.end_time - self.start_time
        return 0
    
    def get_memory_stats(self) -> Dict[str, float]:
        """ë©”ëª¨ë¦¬ í†µê³„"""
        if not self.data['memory_mb']:
            return {}
            
        memory_data = self.data['memory_mb']
        return {
            'min_mb': min(memory_data),
            'max_mb': max(memory_data),
            'avg_mb': sum(memory_data) / len(memory_data),
            'peak_usage_mb': max(memory_data) - min(memory_data),
            'final_mb': memory_data[-1] if memory_data else 0
        }
    
    def get_cpu_stats(self) -> Dict[str, float]:
        """CPU í†µê³„"""
        if not self.data['cpu_percent']:
            return {}
            
        cpu_data = self.data['cpu_percent']
        return {
            'min_percent': min(cpu_data),
            'max_percent': max(cpu_data),
            'avg_percent': sum(cpu_data) / len(cpu_data),
            'peak_usage': max(cpu_data)
        }
    
    def get_api_stats(self) -> Dict[str, Any]:
        """API í˜¸ì¶œ í†µê³„"""
        stats = {}
        
        for api_type, calls in self.api_calls.items():
            if calls:
                durations = [call['duration'] for call in calls]
                successes = [call['success'] for call in calls]
                
                stats[api_type] = {
                    'total_calls': len(calls),
                    'successful_calls': sum(successes),
                    'success_rate': sum(successes) / len(successes) * 100 if successes else 0,
                    'avg_duration': sum(durations) / len(durations) if durations else 0,
                    'total_duration': sum(durations),
                    'min_duration': min(durations) if durations else 0,
                    'max_duration': max(durations) if durations else 0
                }
            else:
                stats[api_type] = {
                    'total_calls': 0,
                    'successful_calls': 0,
                    'success_rate': 0,
                    'avg_duration': 0,
                    'total_duration': 0,
                    'min_duration': 0,
                    'max_duration': 0
                }
        
        return stats
    
    def save_report(self, filename: str = None):
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì €ì¥"""
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"performance_report_{timestamp}.json"
        
        report = {
            'test_name': self.name,
            'start_time': datetime.fromtimestamp(self.start_time).isoformat() if self.start_time else None,
            'end_time': datetime.fromtimestamp(self.end_time).isoformat() if self.end_time else None,
            'duration_seconds': self.get_duration(),
            'memory_stats': self.get_memory_stats(),
            'cpu_stats': self.get_cpu_stats(),
            'api_stats': self.get_api_stats(),
            'raw_data': self.data
        }
        
        os.makedirs('reports', exist_ok=True)
        report_path = os.path.join('reports', filename)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")
        return report_path
    
    def generate_charts(self, output_dir: str = "reports/charts"):
        """ì„±ëŠ¥ ì°¨íŠ¸ ìƒì„±"""
        try:
            import matplotlib
            matplotlib.use('Agg')  # GUI ì—†ëŠ” í™˜ê²½ìš©
            
            os.makedirs(output_dir, exist_ok=True)
            
            # ìŠ¤íƒ€ì¼ ì„¤ì •
            plt.style.use('seaborn-v0_8')
            sns.set_palette("husl")
            
            # 1. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì°¨íŠ¸
            plt.figure(figsize=(12, 6))
            plt.plot(self.data['timestamps'], self.data['memory_mb'], 'b-', linewidth=2, label='ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)')
            plt.fill_between(self.data['timestamps'], self.data['memory_mb'], alpha=0.3)
            plt.xlabel('ì‹œê°„ (ì´ˆ)')
            plt.ylabel('ë©”ëª¨ë¦¬ (MB)')
            plt.title(f'{self.name} - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë³€í™”')
            plt.grid(True, alpha=0.3)
            plt.legend()
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, 'memory_usage.png'), dpi=300, bbox_inches='tight')
            plt.close()
            
            # 2. CPU ì‚¬ìš©ë¥  ì°¨íŠ¸
            plt.figure(figsize=(12, 6))
            plt.plot(self.data['timestamps'], self.data['cpu_percent'], 'r-', linewidth=2, label='CPU ì‚¬ìš©ë¥  (%)')
            plt.fill_between(self.data['timestamps'], self.data['cpu_percent'], alpha=0.3)
            plt.xlabel('ì‹œê°„ (ì´ˆ)')
            plt.ylabel('CPU ì‚¬ìš©ë¥  (%)')
            plt.title(f'{self.name} - CPU ì‚¬ìš©ë¥  ë³€í™”')
            plt.grid(True, alpha=0.3)
            plt.legend()
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, 'cpu_usage.png'), dpi=300, bbox_inches='tight')
            plt.close()
            
            # 3. I/O í™œë™ ì°¨íŠ¸
            plt.figure(figsize=(12, 6))
            plt.plot(self.data['timestamps'], self.data['io_read_bytes'], 'g-', linewidth=2, label='ì½ê¸° (MB)')
            plt.plot(self.data['timestamps'], self.data['io_write_bytes'], 'orange', linewidth=2, label='ì“°ê¸° (MB)')
            plt.xlabel('ì‹œê°„ (ì´ˆ)')
            plt.ylabel('I/O (MB)')
            plt.title(f'{self.name} - I/O í™œë™')
            plt.grid(True, alpha=0.3)
            plt.legend()
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, 'io_activity.png'), dpi=300, bbox_inches='tight')
            plt.close()
            
            # 4. API í˜¸ì¶œ í†µê³„ ì°¨íŠ¸
            api_stats = self.get_api_stats()
            if any(stats['total_calls'] > 0 for stats in api_stats.values()):
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
                
                # API í˜¸ì¶œ íšŸìˆ˜
                apis = list(api_stats.keys())
                calls = [api_stats[api]['total_calls'] for api in apis]
                colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
                
                ax1.bar(apis, calls, color=colors[:len(apis)])
                ax1.set_title('API í˜¸ì¶œ íšŸìˆ˜')
                ax1.set_ylabel('í˜¸ì¶œ ìˆ˜')
                ax1.tick_params(axis='x', rotation=45)
                
                # API ì„±ê³µë¥ 
                success_rates = [api_stats[api]['success_rate'] for api in apis]
                ax2.bar(apis, success_rates, color=colors[:len(apis)])
                ax2.set_title('API ì„±ê³µë¥  (%)')
                ax2.set_ylabel('ì„±ê³µë¥  (%)')
                ax2.set_ylim(0, 100)
                ax2.tick_params(axis='x', rotation=45)
                
                plt.tight_layout()
                plt.savefig(os.path.join(output_dir, 'api_stats.png'), dpi=300, bbox_inches='tight')
                plt.close()
            
            print(f"ğŸ“ˆ ì„±ëŠ¥ ì°¨íŠ¸ ìƒì„± ì™„ë£Œ: {output_dir}")
            
        except ImportError:
            print("ğŸ“Š ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•´ matplotlibê³¼ seabornì„ ì„¤ì¹˜í•˜ì„¸ìš”: pip install matplotlib seaborn")
        except Exception as e:
            print(f"ğŸ“ˆ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def print_summary(self):
        """ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥"""
        print(f"\nğŸ“Š ì„±ëŠ¥ ìš”ì•½ - {self.name}")
        print("="*50)
        
        # ê¸°ë³¸ ì •ë³´
        duration = self.get_duration()
        print(f"â±ï¸  ì´ ì‹¤í–‰ ì‹œê°„: {duration:.2f}ì´ˆ ({duration/60:.1f}ë¶„)")
        
        # ë©”ëª¨ë¦¬ í†µê³„
        memory_stats = self.get_memory_stats()
        if memory_stats:
            print(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
            print(f"   ìµœì†Œ: {memory_stats['min_mb']:.1f}MB")
            print(f"   ìµœëŒ€: {memory_stats['max_mb']:.1f}MB")
            print(f"   í‰ê· : {memory_stats['avg_mb']:.1f}MB")
            print(f"   í”¼í¬ ì¦ê°€: {memory_stats['peak_usage_mb']:.1f}MB")
        
        # CPU í†µê³„
        cpu_stats = self.get_cpu_stats()
        if cpu_stats:
            print(f"ğŸ”¥ CPU ì‚¬ìš©ë¥ :")
            print(f"   ìµœì†Œ: {cpu_stats['min_percent']:.1f}%")
            print(f"   ìµœëŒ€: {cpu_stats['max_percent']:.1f}%")
            print(f"   í‰ê· : {cpu_stats['avg_percent']:.1f}%")
        
        # API í†µê³„
        api_stats = self.get_api_stats()
        total_api_calls = sum(stats['total_calls'] for stats in api_stats.values())
        if total_api_calls > 0:
            print(f"ğŸŒ API í˜¸ì¶œ í†µê³„:")
            print(f"   ì´ í˜¸ì¶œ: {total_api_calls}íšŒ")
            
            for api, stats in api_stats.items():
                if stats['total_calls'] > 0:
                    print(f"   {api}: {stats['total_calls']}íšŒ "
                          f"(ì„±ê³µë¥  {stats['success_rate']:.1f}%, "
                          f"í‰ê·  {stats['avg_duration']:.3f}ì´ˆ)")
        
        # ì„±ëŠ¥ ëª©í‘œ ì²´í¬
        print(f"\nğŸ¯ ì„±ëŠ¥ ëª©í‘œ ì²´í¬:")
        
        # 10ë¶„ ì´ë‚´ ëª©í‘œ
        target_duration = 600  # 10ë¶„
        duration_status = "âœ…" if duration <= target_duration else "âŒ"
        print(f"   {duration_status} ì‹¤í–‰ì‹œê°„: {duration:.1f}ì´ˆ / {target_duration}ì´ˆ")
        
        # 500MB ì´í•˜ ë©”ëª¨ë¦¬ ëª©í‘œ
        if memory_stats:
            max_memory = memory_stats['max_mb']
            memory_target = 500
            memory_status = "âœ…" if max_memory <= memory_target else "âŒ"
            print(f"   {memory_status} ë©”ëª¨ë¦¬: {max_memory:.1f}MB / {memory_target}MB")
        
        # API ì„±ê³µë¥  90% ì´ìƒ ëª©í‘œ
        if api_stats:
            overall_success_rate = sum(stats['successful_calls'] for stats in api_stats.values()) / max(total_api_calls, 1) * 100
            api_status = "âœ…" if overall_success_rate >= 90 else "âŒ"
            print(f"   {api_status} API ì„±ê³µë¥ : {overall_success_rate:.1f}% / 90%")

class EnhancedPipeline(DSNewsPipeline):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì´ ê°€ëŠ¥í•œ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config=None, monitor=None):
        super().__init__(config)
        self.monitor = monitor
    
    def _monitor_api_call(self, api_type: str, func, *args, **kwargs):
        """API í˜¸ì¶œ ëª¨ë‹ˆí„°ë§"""
        if not self.monitor:
            return func(*args, **kwargs)
            
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            duration = time.time() - start_time
            self.monitor.record_api_call(api_type, duration, True, f"Success: {type(result)}")
            return result
        except Exception as e:
            duration = time.time() - start_time
            self.monitor.record_api_call(api_type, duration, False, f"Error: {str(e)}")
            raise

def run_performance_test():
    """ì „ì²´ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ DS News Aggregator ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*60)
    
    # ì„±ëŠ¥ ëª¨ë‹ˆí„° ì´ˆê¸°í™”
    monitor = PerformanceMonitor("DS News Pipeline Performance Test")
    
    try:
        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        monitor.start()
        
        # ê°•í™”ëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        config = Config()
        pipeline = EnhancedPipeline(config, monitor)
        
        print("ğŸ“Š ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰...")
        
        # í…ŒìŠ¤íŠ¸ìš© ì†ŒëŸ‰ ë°ì´í„°ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        stats = pipeline.run_full_pipeline()
        
        print(f"ğŸ‰ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
        print(f"ğŸ“Š ì²˜ë¦¬ëœ ê¸€: {stats.get('final_articles', 0)}ê°œ")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ğŸ’¥ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    finally:
        # ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
        monitor.stop()
        
        # ê²°ê³¼ ì¶œë ¥
        monitor.print_summary()
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        report_path = monitor.save_report()
        
        # ì°¨íŠ¸ ìƒì„±
        monitor.generate_charts()
        
        print(f"\nğŸ“‹ ìƒì„¸ ë¦¬í¬íŠ¸: {report_path}")
        print("ğŸ“ˆ ì„±ëŠ¥ ì°¨íŠ¸: reports/charts/")

def run_memory_stress_test():
    """ë©”ëª¨ë¦¬ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("ğŸ’¾ ë©”ëª¨ë¦¬ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    monitor = PerformanceMonitor("Memory Stress Test")
    monitor.start()
    
    try:
        # ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒì„± ë° ì²˜ë¦¬
        print("ğŸ“Š ëŒ€ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì¤‘...")
        
        test_articles = []
        for i in range(1000):  # 1000ê°œ ê°€ì§œ ê¸€ ìƒì„±
            article = {
                'id': f'stress_test_{i}',
                'title': f'Test Article {i} - ' + 'Long title content ' * 20,
                'content': 'This is a very long test content that simulates real article content. ' * 100,
                'title_ko': f'í…ŒìŠ¤íŠ¸ ê¸€ {i} - ' + 'ê¸´ ì œëª© ë‚´ìš© ' * 20,
                'content_ko': 'ì´ê²ƒì€ ì‹¤ì œ ê¸€ ë‚´ìš©ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ë§¤ìš° ê¸´ í…ŒìŠ¤íŠ¸ ë‚´ìš©ì…ë‹ˆë‹¤. ' * 100,
                'summary': f'Test summary for article {i}. ' * 10,
                'url': f'https://test.com/article/{i}',
                'source': 'test',
                'score': 75 + (i % 25),
                'published': '2024-12-30T08:00:00Z'
            }
            test_articles.append(article)
        
        print(f"ğŸ”„ {len(test_articles)}ê°œ ê¸€ ì²˜ë¦¬ ì¤‘...")
        
        # í•„í„°ë§ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
        from collectors.content_filter import ContentFilter
        content_filter = ContentFilter()
        
        filtered_articles = content_filter.filter_articles(test_articles)
        
        print(f"âœ… {len(filtered_articles)}ê°œ ê¸€ í•„í„°ë§ ì™„ë£Œ")
        
        # ë²ˆì—­ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜ (ì†ŒëŸ‰)
        print("ğŸŒ ë²ˆì—­ ì‹œë®¬ë ˆì´ì…˜...")
        for article in filtered_articles[:10]:  # ìƒìœ„ 10ê°œë§Œ
            # ë²ˆì—­ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ API í˜¸ì¶œ ì—†ì´)
            time.sleep(0.1)  # API ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
        
        print("âœ… ë©”ëª¨ë¦¬ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    finally:
        monitor.stop()
        monitor.print_summary()
        monitor.save_report("memory_stress_test.json")

def benchmark_apis():
    """API ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    print("ğŸ”Œ API ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    
    monitor = PerformanceMonitor("API Benchmark")
    monitor.start()
    
    config = Config()
    
    try:
        # Reddit API ë²¤ì¹˜ë§ˆí¬
        print("ğŸ”´ Reddit API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...")
        from collectors.reddit_collector import RedditCollector
        reddit_collector = RedditCollector(config)
        
        for i in range(3):  # 3íšŒ í…ŒìŠ¤íŠ¸
            start_time = time.time()
            try:
                articles = reddit_collector.collect_from_subreddit('MachineLearning', limit=5)
                duration = time.time() - start_time
                monitor.record_api_call('reddit', duration, True, f"Collected {len(articles)} articles")
                print(f"  Round {i+1}: {duration:.2f}ì´ˆ, {len(articles)}ê°œ ê¸€")
            except Exception as e:
                duration = time.time() - start_time
                monitor.record_api_call('reddit', duration, False, str(e))
                print(f"  Round {i+1}: ì‹¤íŒ¨ - {e}")
            
            time.sleep(2)  # API ì œí•œ ëŒ€ì‘
        
        # Gemini API ë²¤ì¹˜ë§ˆí¬ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        print("ğŸ”µ Gemini API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...")
        from processors.summarizer import Summarizer
        summarizer = Summarizer(config)
        
        test_content = "ë¨¸ì‹ ëŸ¬ë‹ì€ ì¸ê³µì§€ëŠ¥ì˜ í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤. " * 50
        
        for i in range(3):  # 3íšŒ í…ŒìŠ¤íŠ¸
            start_time = time.time()
            try:
                result = summarizer.summarize_text("í…ŒìŠ¤íŠ¸ ì œëª©", test_content)
                duration = time.time() - start_time
                success = result['success']
                monitor.record_api_call('gemini', duration, success, result.get('service', 'unknown'))
                status = "ì„±ê³µ" if success else "ì‹¤íŒ¨"
                print(f"  Round {i+1}: {duration:.2f}ì´ˆ, {status}")
            except Exception as e:
                duration = time.time() - start_time
                monitor.record_api_call('gemini', duration, False, str(e))
                print(f"  Round {i+1}: ì‹¤íŒ¨ - {e}")
                
            time.sleep(3)  # API ì œí•œ ëŒ€ì‘
        
    finally:
        monitor.stop()
        monitor.print_summary()
        monitor.save_report("api_benchmark.json")

if __name__ == '__main__':
    if len(sys.argv) > 1:
        test_type = sys.argv[1].lower()
        
        if test_type == 'memory':
            run_memory_stress_test()
        elif test_type == 'api':
            benchmark_apis()
        elif test_type == 'full':
            run_performance_test()
        else:
            print("ì‚¬ìš©ë²•: python test_performance.py [memory|api|full]")
    else:
        run_performance_test()
